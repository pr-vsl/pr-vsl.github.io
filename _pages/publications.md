---
layout: page
permalink: /publication/
title: publication
description:
nav: true
nav_order: 4
---


{% details Journal %}

<ol class=space_list>

<li> Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://www.sciencedirect.com/science/article/abs/pii/S016786552300199X" target="_blank">"Prediction of Evoked Expression from Videos with Temporal Position Fusion"</a>, <font color="ff00ff"><i>Pattern Recognition Letters</i></font>, Vol. 172, pp. 245-251, August 2023. (2023 IF: 5.1). </li>

<li>J.P.J. Prioli, S. Liu, Y. Shen, Van Thong Huynh, J. Rickli , Hyung-Jeong Yang, Soo-Hyung Kim, Kyoung-Yun Kim, <a href="https://dl.acm.org/doi/abs/10.3233/JID-221012" target="_blank">“Empirical study for worker engagement in collaborative robot programming”</a>,  <font color="ff00ff"><i>Journal of
Integrated Design and Process Science</i></font>, Vol. 26, no. 2, pp. 159-181, 2023. (2023 IF: 0.6). </li>

<li>Huynh Van Thong, Hyung-Jeong Yang, Guee-Sang Lee, Soo Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9431699" target="_blank">“End-to-End Learning for Multimodal Emotion Recognition in Video with Adaptive Loss”</a>, <font color="ff00ff"><i>IEEE MultiMedia</i></font>, Vol. 28, No. 2, pp. 59-66, April-June 2021. (2021 IF: 5.633, JCR10%). </li>

<li>Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9143078" target="_blank">"Semantic Segmentation of the Eye with a Lightweight Deep Network and Shape Correction"</a>, <font color="ff00ff"><i>IEEE Access</i></font>, Vol. 8, pp. 131967-131974, July 2020. (2020 IF: 3.367).
</li>

</ol>
{% enddetails %}

{% details Conference %}

<ol class=space_list>

<li>Ngoc Tu Vu, Van Thong Huynh, Hyung-Jeong Yang and Soo-Hyung Kim, <a href="https://link.springer.com/chapter/10.1007/978-3-031-47665-5_10" target="_blank">"Multiscale Transformer-Based for Multimodal Affective States Estimation from Physiological Signals"</a>, <font color="ff00ff"><i>Proc. 2023 Asian Conference on Pattern Recognition</i> (ACPR 2023)</font>, Lecture Notes in Computer Science (Springer), vol 14408, pp. 113-122, Kitakyushu, Japan, Nov. 2023. </li>

<li>Nguyen Quang Vinh, Van Thong Huynh, Soo-Hyung Kim,  <a href="https://proceedings.bmvc2023.org/806/" target="_blank">"Adapt Distinct Semantics for Uncertain Areas in Polyp Segmentation"</a>, <i><font color="ff00ff">Proc. 2023 Britich Machine Vision Conference</font></i> (BMVC 2023), Aberdeen,  UK, Nov. 2023. </li>

<li>Ngoc Tu Vu, Van Thong Huynh, Hyung-Jeong Yang, Soo-Hyung Kim, Shah Nawaz, Karthik Nandakumar, M. Zaigham Zaheer, <a href="https://dl.acm.org/doi/10.1145/3581783.3612857" target="_blank">“DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation”</a>, <i><font color="ff00ff">Proc. 31st ACM Int. Conf. Multimedia</font></i>, pp.  9521–9525, Ottawa, Canada, Oct. 2023. </li>

<li>Ngoc Tu Vu, Van Thong Huynh, Trong Nghia Nguyen, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/10208411" target="_blank">"Ensemble Spatial and Temporal Vision Transformer for Action Units Detection"</a>, <i>Proc. CVPR 2023  Workshop and Competition on Affective Behavior Analysis in-the-wild</i>, pp. 5769-5775, Vancouver, Canada, June 2023. </li>

<li>Kim Ngan Phan, Hong-Hai Nguyen, Van-Thong Huynh, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9856987" target="_blank">"Facial Expression Classification using Fusion of Deep Neural Network in Video"</a>, <i>Proc. CVPR Workshop and Competition on Affective Behavior Analysis in-the-wild </i>(ABAW), pp. 2506-2510, New Orleans, USA, June 2022. </li>

<li>Hong-Hai Nguyen, Van-Thong Huynh, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/abstract/document/9857161" target="_blank">"An Ensemble Approach for Facial Expression Analysis and Action Unit Detection in-the-wild Video"</a>, <i>Proc. CVPR Workshop and Competition on Affective Behavior Analysis in-the-wild</i> (ABAW), pp. 2511-2516, New Orleans, USA, June 2022. </li>

<li>Songa Kim, Van Thong Huynh, Dung Tran Thi, Aran Oh, Guee-Sang Lee, Hyung-Jeong Yang, and Soo-Hyung Kim, <a href="https://link.springer.com/chapter/10.1007/978-3-030-81638-4_14" target="_blank">"The 2nd Korean Emotion Recognition Challenge: Methods and Results"</a>, <i>Proc. Int. Workshop on Frontiers in Computer Vision</i>(IWFCV 2021), Daegu, Korea, pp. 176-183, Feb. 2021. </li>

<li>Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9320185" target="_blank">"Multimodality Pain and related Behaviors Recognition based on Attention Learning"</a>, <font color="ff00ff"><i>Proc. 15th IEEE International Conference on Automatic Face and Gesture Recognition</i></font> (FG 2020), doi: 10.1109/FG47880.2020.00034, pp. 814-818, Buenos Aires, Argentina, Nov. 2020. </li>

<li>Van Thong Huynh, Aran Oh, Soo-Hyung Kim, Guee-Sang Lee, and Hyung-Jeong Yang, "Estimate Engagement Intensity with Eye Movements," <i>Proc. Int. Workshop on Frontiers in Computer Vision</i>(IWFCV 2020), Kagoshima, Japan, Feb. 2020.
</li>

<li>Van Thong Huynh, Soo-Hyung Kim, Guee-Sang Lee, Hyung-Jeong Yang, <a href="https://ieeexplore.ieee.org/document/9022251" target="_blank">"Eye Semantic Segmentation with A Lightweight Model"</a>, <font color="ff00ff"><i>Proc. 2019 IEEE Int. Conf. Computer Vision Workshop - Eye Tracking for VR and AR </i>(ICCVW 2019)</font>, pp. 3704-3707, Seoul, Korea, Nov. 2019.
</li>

<li>Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://dl.acm.org/doi/abs/10.1145/3340555.3355714" target="_blank">"Engagement Intensity Prediction with Facial Behavior Features"</a>, <font color="ff00ff"><i>Proc. 2019 ACM Int. Conf. Multimodal Interaction</i>(ICMI 2019)</font>, pp. 567-571, Suzhou, China, Oct. 2019. </li>

</ol>
{% enddetails %}

{% details Patent %}
{% enddetails %}
