---
layout: page
permalink: /publication/
title: publication
description:
nav: true
nav_order: 4
---


{% details Journal %}
<ol class=space_list>
<li>Van Thong Huynh, Seungwon Kim, Hyung-Jeong Yang, Soo-Hyung Kim, <a href="https://doi.org/10.1016/j.cviu.2025.104429" target="_blank">"Multilevel Spatial-Temporal Feature Analysis for Generic Event Boundary Detection in Videos"</a>, <font color="ff00ff"><i>Computer Vision and Image Understanding, 259 (2025) 104429.</i></font> </li>
  
<li>Trong-Nghia Nguyen, Soo-Hyung Kim, Bo-Gun Kho, Van-Thien Luong, Hong-Hai Nguyen, Van Thong Huynh, <a href="/">"AI-Driven Early Warning Systems in Emergency Care: Implementing a Multi-Gradient Network for Real-Time Clinical Deterioration Prediction"</a>, <font color="ff00ff"><i>Journal Submitted, 2025.</i></font> </li>

<li>Nicholas A Coles, Bartosz Perz, Maciej Behnke, Johannes C. Eichstaedt, Soo-Hyung Kim, Tu N Vu, Chirag Raman, Julian Tejada, Van Thong Huynh, et al., <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.241778" target="_blank">"Big team science reveals promises and limitations of machine learning efforts to model the physiological basis of affective experience"</a>, <font color="ff00ff"><i>Royal Society Open Science, 12 (6) 241778, June 2025.</i></font> </li>
  
<li> Ngoc Tu Vu, Van Thong Huynh, Seung Won Kim, Ji Eun Shin, Hyung-Jeong Yang, Soo-Hyung Kim, <a href="https://www.sciencedirect.com/science/article/pii/S1746809425003428" target="_blank">"Switch Fusion for Continuous Emotion Estimation from Multiple Physiological Signals"</a>, <font color="ff00ff"><i>Biomedical Signal Processing and Control, 107 (2025) 107831.</i></font> </li>

<li> Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://www.sciencedirect.com/science/article/abs/pii/S016786552300199X" target="_blank">"Prediction of Evoked Expression from Videos with Temporal Position Fusion"</a>, <font color="ff00ff"><i>Pattern Recognition Letters</i></font>, Vol. 172, pp. 245-251, August 2023. (2023 IF: 5.1). <a href="/publication/evoked_prl23/">[project page]</a> </li>

<li>J.P.J. Prioli, S. Liu, Y. Shen, Van Thong Huynh, J. Rickli , Hyung-Jeong Yang, Soo-Hyung Kim, Kyoung-Yun Kim, <a href="https://dl.acm.org/doi/abs/10.3233/JID-221012" target="_blank">“Empirical study for worker engagement in collaborative robot programming”</a>,  <font color="ff00ff"><i>Journal of
Integrated Design and Process Science</i></font>, Vol. 26, no. 2, pp. 159-181, 2023. (2023 IF: 0.6). </li>

<li>Huynh Van Thong, Hyung-Jeong Yang, Guee-Sang Lee, Soo Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9431699" target="_blank">“End-to-End Learning for Multimodal Emotion Recognition in Video with Adaptive Loss”</a>, <font color="ff00ff"><i>IEEE MultiMedia</i></font>, Vol. 28, No. 2, pp. 59-66, April-June 2021. (2021 IF: 5.633, JCR10%). <a href="/publication/e2e_mm21/">[project page]</a> </li>

<li>Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9143078" target="_blank">"Semantic Segmentation of the Eye with a Lightweight Deep Network and Shape Correction"</a>, <font color="ff00ff"><i>IEEE Access</i></font>, Vol. 8, pp. 131967-131974, July 2020. (2020 IF: 3.367). 
</li>

</ol>
{% enddetails %}

{% details Conference %}
<ol class=space_list>

<li>Trong-Nghia Nguyen, Hong-Hai Nguyen, Ngoc Tu Vu, Tuan Anh Tran, Soo-Hyung Kim, Bo-Gun Kho and Van-Thong Huynh, <a href="https://link.springer.com/chapter/10.1007/978-981-95-4963-4_10" target="_blank">"MediFusion-Flex: An Adaptive Multimodal Deep Learning Framework for Clinical Deterioration Prediction in Emergency Medicine"</a>, <i>International Conference on Multi-disciplinary Trends in Artificial Intelligence</i>, Lecture Notes in Computer Science (Springer), vol 16355, pp. xx–xx, Dec. 2025. </li>

<li>Phuc Thanh Danh Nguyen, Nhu Tinh Anh Nguyen, Hong Tai Tran, Van Thong Huynh, Tuan-Anh Tran and Xuan Toan Mai, <a href="https://link.springer.com/chapter/10.1007/978-981-95-3355-8_31" target="_blank">"ChartLite: Simplified End-to-End Extraction of Chart Data for Enhanced Visual Understanding"</a>, <i>International Conference on Intelligent Systems and Data Science</i>, Communications in Computer and Information Science (Springer), vol 2713, pp. 429–443, Oct. 2025. </li>

<li>Dang Hien Long Tran, Ho Duc An Nguyen, Van Thong Huynh, Tuan-Anh Tran, Xuan Toan Mai and Hong Tai Tran, <a href="https://link.springer.com/chapter/10.1007/978-981-95-3355-8_30" target="_blank">"Enhanced Chart Detection in Document Images with Segmentation Backbone"</a>, <i>International Conference on Intelligent Systems and Data Science</i>, Communications in Computer and Information Science (Springer), vol 2713, pp. 414–428, Oct. 2025. </li>

<li>Ngoc Tu Vu, Van Thong Huynh, Hyung-Jeong Yang and Soo-Hyung Kim, <a href="https://link.springer.com/chapter/10.1007/978-3-031-47665-5_10" target="_blank">"Multiscale Transformer-Based for Multimodal Affective States Estimation from Physiological Signals"</a>, <font color="ff00ff"><i>Proc. 2023 Asian Conference on Pattern Recognition</i> (ACPR 2023)</font>, Lecture Notes in Computer Science (Springer), vol 14408, pp. 113-122, Kitakyushu, Japan, Nov. 2023. </li>

<li>Nguyen Quang Vinh, Van Thong Huynh, Soo-Hyung Kim,  <a href="https://proceedings.bmvc2023.org/806/" target="_blank">"Adapt Distinct Semantics for Uncertain Areas in Polyp Segmentation"</a>, <i><font color="ff00ff">Proc. 2023 Britich Machine Vision Conference</font></i> (BMVC 2023), Aberdeen,  UK, Nov. 2023. </li>

<li>Ngoc Tu Vu, Van Thong Huynh, Hyung-Jeong Yang, Soo-Hyung Kim, Shah Nawaz, Karthik Nandakumar, M. Zaigham Zaheer, <a href="https://dl.acm.org/doi/10.1145/3581783.3612857" target="_blank">“DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation”</a>, <i><font color="ff00ff">Proc. 31st ACM Int. Conf. Multimedia</font></i>, pp.  9521–9525, Ottawa, Canada, Oct. 2023. </li>

<li>Ngoc Tu Vu, Van Thong Huynh, Trong Nghia Nguyen, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/10208411" target="_blank">"Ensemble Spatial and Temporal Vision Transformer for Action Units Detection"</a>, <i>Proc. CVPR 2023  Workshop and Competition on Affective Behavior Analysis in-the-wild</i>, pp. 5769-5775, Vancouver, Canada, June 2023. </li>

<li>Kim Ngan Phan, Hong-Hai Nguyen, Van-Thong Huynh, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9856987" target="_blank">"Facial Expression Classification using Fusion of Deep Neural Network in Video"</a>, <i>Proc. CVPR Workshop and Competition on Affective Behavior Analysis in-the-wild </i>(ABAW), pp. 2506-2510, New Orleans, USA, June 2022. </li>

<li>Hong-Hai Nguyen, Van-Thong Huynh, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/abstract/document/9857161" target="_blank">"An Ensemble Approach for Facial Expression Analysis and Action Unit Detection in-the-wild Video"</a>, <i>Proc. CVPR Workshop and Competition on Affective Behavior Analysis in-the-wild</i> (ABAW), pp. 2511-2516, New Orleans, USA, June 2022. </li>

<li>Songa Kim, Van Thong Huynh, Dung Tran Thi, Aran Oh, Guee-Sang Lee, Hyung-Jeong Yang, and Soo-Hyung Kim, <a href="https://link.springer.com/chapter/10.1007/978-3-030-81638-4_14" target="_blank">"The 2nd Korean Emotion Recognition Challenge: Methods and Results"</a>, <i>Proc. Int. Workshop on Frontiers in Computer Vision</i>(IWFCV 2021), Daegu, Korea, pp. 176-183, Feb. 2021. </li>

<li>Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://ieeexplore.ieee.org/document/9320185" target="_blank">"Multimodality Pain and related Behaviors Recognition based on Attention Learning"</a>, <font color="ff00ff"><i>Proc. 15th IEEE International Conference on Automatic Face and Gesture Recognition</i></font> (FG 2020), doi: 10.1109/FG47880.2020.00034, pp. 814-818, Buenos Aires, Argentina, Nov. 2020. <a href="/publication/emopain_fg20/">[project page]</a> </li>

<li>Van Thong Huynh, Aran Oh, Soo-Hyung Kim, Guee-Sang Lee, and Hyung-Jeong Yang, "Estimate Engagement Intensity with Eye Movements," <i>Proc. Int. Workshop on Frontiers in Computer Vision</i>(IWFCV 2020), Kagoshima, Japan, Feb. 2020.
</li>

<li>Van Thong Huynh, Soo-Hyung Kim, Guee-Sang Lee, Hyung-Jeong Yang, <a href="https://ieeexplore.ieee.org/document/9022251" target="_blank">"Eye Semantic Segmentation with A Lightweight Model"</a>, <font color="ff00ff"><i>Proc. 2019 IEEE Int. Conf. Computer Vision Workshop - Eye Tracking for VR and AR </i>(ICCVW 2019)</font>, pp. 3704-3707, Seoul, Korea, Nov. 2019.
</li>

<li>Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, Soo-Hyung Kim, <a href="https://dl.acm.org/doi/abs/10.1145/3340555.3355714" target="_blank">"Engagement Intensity Prediction with Facial Behavior Features"</a>, <font color="ff00ff"><i>Proc. 2019 ACM Int. Conf. Multimodal Interaction</i>(ICMI 2019)</font>, pp. 567-571, Suzhou, China, Oct. 2019. <a href="/publication/eg_emotiw19/">[project page]</a> </li>

</ol>
{% enddetails %}

{% details Patent %}
<ol class=space_list>
  
<li>Kim, S. H., Lee, G. S., Yang, H. J., Huynh, V. T., & Oh, A. R. (2021), <a href="https://doi.org/10.8080/1020190089540" target="_blank"> "Apparatus and Method for Identifying Emotion by Gaze Movement Analysis"</a>, <font color="ff00ff"> Korea Patent Registration Number: 10‑2204743</font>. Technology transfer: MayfarmSoft ‑ September 2020.</li>

</ol>
{% enddetails %}
